{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart project\n"
     ]
    }
   ],
   "source": [
    "print(\"Walmart project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Data Exploration & Leading-- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the liabrary that Needed.\n",
    "import pandas as pd\n",
    "\n",
    "## FOR MYSQL toolkit    \n",
    "import pymysql # This will work as adapter\n",
    "from sqlalchemy import create_engine \n",
    "\n",
    "### FOR Postresql\n",
    "import psycopg2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10051, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Walmart.csv', encoding_errors='ignore')\n",
    "\n",
    "df.shape ### It show the total no. of rows and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>category</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>rating</th>\n",
       "      <th>profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WALM003</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>$74.69</td>\n",
       "      <td>7.0</td>\n",
       "      <td>05/01/19</td>\n",
       "      <td>13:08:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WALM048</td>\n",
       "      <td>Harlingen</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>$15.28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>08/03/19</td>\n",
       "      <td>10:29:00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WALM067</td>\n",
       "      <td>Haltom City</td>\n",
       "      <td>Home and lifestyle</td>\n",
       "      <td>$46.33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>03/03/19</td>\n",
       "      <td>13:23:00</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WALM064</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>$58.22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27/01/19</td>\n",
       "      <td>20:33:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WALM013</td>\n",
       "      <td>Irving</td>\n",
       "      <td>Sports and travel</td>\n",
       "      <td>$86.31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>08/02/19</td>\n",
       "      <td>10:37:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_id   Branch         City                category unit_price  \\\n",
       "0           1  WALM003  San Antonio       Health and beauty     $74.69   \n",
       "1           2  WALM048    Harlingen  Electronic accessories     $15.28   \n",
       "2           3  WALM067  Haltom City      Home and lifestyle     $46.33   \n",
       "3           4  WALM064      Bedford       Health and beauty     $58.22   \n",
       "4           5  WALM013       Irving       Sports and travel     $86.31   \n",
       "\n",
       "   quantity      date      time payment_method  rating  profit_margin  \n",
       "0       7.0  05/01/19  13:08:00        Ewallet     9.1           0.48  \n",
       "1       5.0  08/03/19  10:29:00           Cash     9.6           0.48  \n",
       "2       7.0  03/03/19  13:23:00    Credit card     7.4           0.33  \n",
       "3       8.0  27/01/19  20:33:00        Ewallet     8.4           0.33  \n",
       "4       7.0  08/02/19  10:37:00        Ewallet     5.3           0.48  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>rating</th>\n",
       "      <th>profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10051.000000</td>\n",
       "      <td>10020.000000</td>\n",
       "      <td>10051.000000</td>\n",
       "      <td>10051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5025.741220</td>\n",
       "      <td>2.353493</td>\n",
       "      <td>5.825659</td>\n",
       "      <td>0.393791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2901.174372</td>\n",
       "      <td>1.602658</td>\n",
       "      <td>1.763991</td>\n",
       "      <td>0.090669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2513.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5026.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7538.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         invoice_id      quantity        rating  profit_margin\n",
       "count  10051.000000  10020.000000  10051.000000   10051.000000\n",
       "mean    5025.741220      2.353493      5.825659       0.393791\n",
       "std     2901.174372      1.602658      1.763991       0.090669\n",
       "min        1.000000      1.000000      3.000000       0.180000\n",
       "25%     2513.500000      1.000000      4.000000       0.330000\n",
       "50%     5026.000000      2.000000      6.000000       0.330000\n",
       "75%     7538.500000      3.000000      7.000000       0.480000\n",
       "max    10000.000000     10.000000     10.000000       0.570000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() #It shows the counts of every rows and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10051 entries, 0 to 10050\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   invoice_id      10051 non-null  int64  \n",
      " 1   Branch          10051 non-null  object \n",
      " 2   City            10051 non-null  object \n",
      " 3   category        10051 non-null  object \n",
      " 4   unit_price      10020 non-null  object \n",
      " 5   quantity        10020 non-null  float64\n",
      " 6   date            10051 non-null  object \n",
      " 7   time            10051 non-null  object \n",
      " 8   payment_method  10051 non-null  object \n",
      " 9   rating          10051 non-null  float64\n",
      " 10  profit_margin   10051 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 863.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Checking Data types.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(51)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All duplicates records, .sum() counts all the true and shows the list.\n",
    "df.duplicated() .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invoice_id         0\n",
       "Branch             0\n",
       "City               0\n",
       "category           0\n",
       "unit_price        31\n",
       "quantity          31\n",
       "date               0\n",
       "time               0\n",
       "payment_method     0\n",
       "rating             0\n",
       "profit_margin      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in records.  \n",
    "df.isnull() .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Droping all the duplicates values.\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print to check\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invoice_id         0\n",
       "Branch             0\n",
       "City               0\n",
       "category           0\n",
       "unit_price        31\n",
       "quantity          31\n",
       "date               0\n",
       "time               0\n",
       "payment_method     0\n",
       "rating             0\n",
       "profit_margin      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape to see the updated records that drop duplicates\n",
    "df.shape\n",
    "\n",
    "# Now, only null values left. There is two choices either we replace the null value or drop the null values.\n",
    "df.isnull() .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9969, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping all rows with missing reports\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Now the null is removed\n",
    "df.isnull() .sum()\n",
    "\n",
    "# All the no. of records are reduced from the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '$74.69'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m df.dtypes\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Using .astype to type caste the it's data type into float.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munit_price\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Then it will give error, ValueError: could not convert string to float: '$74.69' due to '$' sign, bcoz it can't convert into int or float.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\OneDrive\\Desktop\\Project-Walmart\\my_env1\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6637\u001b[39m     results = [\n\u001b[32m   6638\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6639\u001b[39m     ]\n\u001b[32m   6641\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6642\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6643\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6644\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\OneDrive\\Desktop\\Project-Walmart\\my_env1\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\OneDrive\\Desktop\\Project-Walmart\\my_env1\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\OneDrive\\Desktop\\Project-Walmart\\my_env1\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    756\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    762\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\OneDrive\\Desktop\\Project-Walmart\\my_env1\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\OneDrive\\Desktop\\Project-Walmart\\my_env1\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\OneDrive\\Desktop\\Project-Walmart\\my_env1\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '$74.69'"
     ]
    }
   ],
   "source": [
    "# Now only left to change the data type of 'unit_price'\n",
    "df.dtypes\n",
    "\n",
    "# Using .astype to type caste the it's data type into float.\n",
    "df['unit_price'].astype(float)\n",
    "# Then it will give error, ValueError: could not convert string to float: '$74.69' due to '$' sign, bcoz it can't convert into int or float.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>category</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>rating</th>\n",
       "      <th>profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WALM003</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>74.69</td>\n",
       "      <td>7.0</td>\n",
       "      <td>05/01/19</td>\n",
       "      <td>13:08:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WALM048</td>\n",
       "      <td>Harlingen</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>15.28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>08/03/19</td>\n",
       "      <td>10:29:00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WALM067</td>\n",
       "      <td>Haltom City</td>\n",
       "      <td>Home and lifestyle</td>\n",
       "      <td>46.33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>03/03/19</td>\n",
       "      <td>13:23:00</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WALM064</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>58.22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27/01/19</td>\n",
       "      <td>20:33:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WALM013</td>\n",
       "      <td>Irving</td>\n",
       "      <td>Sports and travel</td>\n",
       "      <td>86.31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>08/02/19</td>\n",
       "      <td>10:37:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_id   Branch         City                category  unit_price  \\\n",
       "0           1  WALM003  San Antonio       Health and beauty       74.69   \n",
       "1           2  WALM048    Harlingen  Electronic accessories       15.28   \n",
       "2           3  WALM067  Haltom City      Home and lifestyle       46.33   \n",
       "3           4  WALM064      Bedford       Health and beauty       58.22   \n",
       "4           5  WALM013       Irving       Sports and travel       86.31   \n",
       "\n",
       "   quantity      date      time payment_method  rating  profit_margin  \n",
       "0       7.0  05/01/19  13:08:00        Ewallet     9.1           0.48  \n",
       "1       5.0  08/03/19  10:29:00           Cash     9.6           0.48  \n",
       "2       7.0  03/03/19  13:23:00    Credit card     7.4           0.33  \n",
       "3       8.0  27/01/19  20:33:00        Ewallet     8.4           0.33  \n",
       "4       7.0  08/02/19  10:37:00        Ewallet     5.3           0.48  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will replace $ sign with nothing.\n",
    "df['unit_price'].str.replace('$','')\n",
    "\n",
    "# Assigning back to the same column to implemented in the dataset, you can say TO SAVE THE REPLACE.\n",
    "df['unit_price']=df['unit_price'].str.replace('$','').astype(float)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['invoice_id', 'Branch', 'City', 'category', 'unit_price', 'quantity',\n",
       "       'date', 'time', 'payment_method', 'rating', 'profit_margin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total column in datasets\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['invoice_id', 'branch', 'city', 'category', 'unit_price', 'quantity',\n",
       "       'date', 'time', 'payment_method', 'rating', 'profit_margin', 'total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Converting Branch and City column into lower case to match the parameters.\n",
    "df.columns=df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>category</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>rating</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WALM003</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>74.69</td>\n",
       "      <td>7.0</td>\n",
       "      <td>05/01/19</td>\n",
       "      <td>13:08:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>522.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WALM048</td>\n",
       "      <td>Harlingen</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>15.28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>08/03/19</td>\n",
       "      <td>10:29:00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>76.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WALM067</td>\n",
       "      <td>Haltom City</td>\n",
       "      <td>Home and lifestyle</td>\n",
       "      <td>46.33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>03/03/19</td>\n",
       "      <td>13:23:00</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.33</td>\n",
       "      <td>324.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WALM064</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>58.22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27/01/19</td>\n",
       "      <td>20:33:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.33</td>\n",
       "      <td>465.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WALM013</td>\n",
       "      <td>Irving</td>\n",
       "      <td>Sports and travel</td>\n",
       "      <td>86.31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>08/02/19</td>\n",
       "      <td>10:37:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>604.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_id   Branch         City                category  unit_price  \\\n",
       "0           1  WALM003  San Antonio       Health and beauty       74.69   \n",
       "1           2  WALM048    Harlingen  Electronic accessories       15.28   \n",
       "2           3  WALM067  Haltom City      Home and lifestyle       46.33   \n",
       "3           4  WALM064      Bedford       Health and beauty       58.22   \n",
       "4           5  WALM013       Irving       Sports and travel       86.31   \n",
       "\n",
       "   quantity      date      time payment_method  rating  profit_margin   total  \n",
       "0       7.0  05/01/19  13:08:00        Ewallet     9.1           0.48  522.83  \n",
       "1       5.0  08/03/19  10:29:00           Cash     9.6           0.48   76.40  \n",
       "2       7.0  03/03/19  13:23:00    Credit card     7.4           0.33  324.31  \n",
       "3       8.0  27/01/19  20:33:00        Ewallet     8.4           0.33  465.76  \n",
       "4       7.0  08/02/19  10:37:00        Ewallet     5.3           0.48  604.17  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new column Total that multiply the unit_price and quantity.\n",
    "df['total'] = df['unit_price'] * df['quantity']\n",
    "\n",
    "# And new column added\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Data extraction is done, data cleaning is done and it's formating is also done.\n",
    "# Now we will use SQL liabraries to export the data in MySQL Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### For mysql credintional\n",
    "# mysql\n",
    "# host = localhost\n",
    "# port = 3306\n",
    "# user = root\n",
    "# password = '1234'\n",
    "\n",
    "##### For Postresql credintional\n",
    "# postreSQL\n",
    "# host = localhost\n",
    "# port = 5432\n",
    "# user = postgres\n",
    "# password = '1234'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the clean CSV file \n",
    "df.to_csv('walmart_clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success\n"
     ]
    }
   ],
   "source": [
    "#mysql connection.\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Correct connection string\n",
    "engine_mysql = create_engine(\"mysql+pymysql://root:1234@localhost:3306/walmart_db\")\n",
    "\n",
    "try:\n",
    "    engine_mysql\n",
    "    print(\"Connection Success\")\n",
    "except:\n",
    "    print(\"Unable to Connect\")    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success to psql\n"
     ]
    }
   ],
   "source": [
    "#Postresql connection.\n",
    "\n",
    "import psycopg2 \n",
    "# Correct connection string\n",
    "engine_psql = create_engine(\"postgresql+psycopg2://postgres:1111@localhost:5432/walmart_db\")\n",
    "\n",
    "try:\n",
    "    engine_psql\n",
    "    print(\"Connection Success to psql\")\n",
    "except:\n",
    "    print(\"Unable to Connect\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_sql in module pandas.core.generic:\n",
      "\n",
      "to_sql(name: 'str', con, *, schema: 'str | None' = None, if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail', index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, chunksize: 'int | None' = None, dtype: 'DtypeArg | None' = None, method: \"Literal['multi'] | Callable | None\" = None) -> 'int | None' method of pandas.core.frame.DataFrame instance\n",
      "    Write records stored in a DataFrame to a SQL database.\n",
      "    \n",
      "    Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      "    newly created, appended to, or overwritten.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    name : str\n",
      "        Name of SQL table.\n",
      "    con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      "        Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "        library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      "        is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      "        connectable. See `here                 <https://docs.sqlalchemy.org/en/20/core/connections.html>`_.\n",
      "        If passing a sqlalchemy.engine.Connection which is already in a transaction,\n",
      "        the transaction will not be committed.  If passing a sqlite3.Connection,\n",
      "        it will not be possible to roll back the record insertion.\n",
      "    \n",
      "    schema : str, optional\n",
      "        Specify the schema (if database flavor supports this). If None, use\n",
      "        default schema.\n",
      "    if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "        How to behave if the table already exists.\n",
      "    \n",
      "        * fail: Raise a ValueError.\n",
      "        * replace: Drop the table before inserting new values.\n",
      "        * append: Insert new values to the existing table.\n",
      "    \n",
      "    index : bool, default True\n",
      "        Write DataFrame index as a column. Uses `index_label` as the column\n",
      "        name in the table. Creates a table index for this column.\n",
      "    index_label : str or sequence, default None\n",
      "        Column label for index column(s). If None is given (default) and\n",
      "        `index` is True, then the index names are used.\n",
      "        A sequence should be given if the DataFrame uses MultiIndex.\n",
      "    chunksize : int, optional\n",
      "        Specify the number of rows in each batch to be written at a time.\n",
      "        By default, all rows will be written at once.\n",
      "    dtype : dict or scalar, optional\n",
      "        Specifying the datatype for columns. If a dictionary is used, the\n",
      "        keys should be the column names and the values should be the\n",
      "        SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      "        scalar is provided, it will be applied to all columns.\n",
      "    method : {None, 'multi', callable}, optional\n",
      "        Controls the SQL insertion clause used:\n",
      "    \n",
      "        * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      "        * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      "        * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      "    \n",
      "        Details and a sample callable implementation can be found in the\n",
      "        section :ref:`insert method <io.sql.method>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or int\n",
      "        Number of rows affected by to_sql. None is returned if the callable\n",
      "        passed into ``method`` does not return an integer number of rows.\n",
      "    \n",
      "        The number of returned rows affected is the sum of the ``rowcount``\n",
      "        attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not\n",
      "        reflect the exact number of written rows as stipulated in the\n",
      "        `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
      "        `SQLAlchemy <https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.CursorResult.rowcount>`__.\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        When the table already exists and `if_exists` is 'fail' (the\n",
      "        default).\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_sql : Read a DataFrame from a table.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Timezone aware datetime columns will be written as\n",
      "    ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      "    database. Otherwise, the datetimes will be stored as timezone unaware\n",
      "    timestamps local to the original timezone.\n",
      "    \n",
      "    Not all datastores support ``method=\"multi\"``. Oracle, for example,\n",
      "    does not support multi-value insert.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] https://docs.sqlalchemy.org\n",
      "    .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Create an in-memory SQLite database.\n",
      "    \n",
      "    >>> from sqlalchemy import create_engine\n",
      "    >>> engine = create_engine('sqlite://', echo=False)\n",
      "    \n",
      "    Create a table from scratch with 3 rows.\n",
      "    \n",
      "    >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      "    >>> df\n",
      "         name\n",
      "    0  User 1\n",
      "    1  User 2\n",
      "    2  User 3\n",
      "    \n",
      "    >>> df.to_sql(name='users', con=engine)\n",
      "    3\n",
      "    >>> from sqlalchemy import text\n",
      "    >>> with engine.connect() as conn:\n",
      "    ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      "    \n",
      "    An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      "    \n",
      "    >>> with engine.begin() as connection:\n",
      "    ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      "    ...     df1.to_sql(name='users', con=connection, if_exists='append')\n",
      "    2\n",
      "    \n",
      "    This is allowed to support operations that require that the same\n",
      "    DBAPI connection is used for the entire operation.\n",
      "    \n",
      "    >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      "    >>> df2.to_sql(name='users', con=engine, if_exists='append')\n",
      "    2\n",
      "    >>> with engine.connect() as conn:\n",
      "    ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      "     (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      "     (1, 'User 7')]\n",
      "    \n",
      "    Overwrite the table with just ``df2``.\n",
      "    \n",
      "    >>> df2.to_sql(name='users', con=engine, if_exists='replace',\n",
      "    ...            index_label='id')\n",
      "    2\n",
      "    >>> with engine.connect() as conn:\n",
      "    ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      "    [(0, 'User 6'), (1, 'User 7')]\n",
      "    \n",
      "    Use ``method`` to define a callable insertion method to do nothing\n",
      "    if there's a primary key conflict on a table in a PostgreSQL database.\n",
      "    \n",
      "    >>> from sqlalchemy.dialects.postgresql import insert\n",
      "    >>> def insert_on_conflict_nothing(table, conn, keys, data_iter):\n",
      "    ...     # \"a\" is the primary key in \"conflict_table\"\n",
      "    ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
      "    ...     stmt = insert(table.table).values(data).on_conflict_do_nothing(index_elements=[\"a\"])\n",
      "    ...     result = conn.execute(stmt)\n",
      "    ...     return result.rowcount\n",
      "    >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_nothing)  # doctest: +SKIP\n",
      "    0\n",
      "    \n",
      "    For MySQL, a callable to update columns ``b`` and ``c`` if there's a conflict\n",
      "    on a primary key.\n",
      "    \n",
      "    >>> from sqlalchemy.dialects.mysql import insert\n",
      "    >>> def insert_on_conflict_update(table, conn, keys, data_iter):\n",
      "    ...     # update columns \"b\" and \"c\" on primary key conflict\n",
      "    ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
      "    ...     stmt = (\n",
      "    ...         insert(table.table)\n",
      "    ...         .values(data)\n",
      "    ...     )\n",
      "    ...     stmt = stmt.on_duplicate_key_update(b=stmt.inserted.b, c=stmt.inserted.c)\n",
      "    ...     result = conn.execute(stmt)\n",
      "    ...     return result.rowcount\n",
      "    >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_update)  # doctest: +SKIP\n",
      "    2\n",
      "    \n",
      "    Specify the dtype (especially useful for integers with missing values).\n",
      "    Notice that while pandas is forced to store the data as floating point,\n",
      "    the database supports nullable integers. When fetching the data with\n",
      "    Python, we get back integer scalars.\n",
      "    \n",
      "    >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      "    >>> df\n",
      "         A\n",
      "    0  1.0\n",
      "    1  NaN\n",
      "    2  2.0\n",
      "    \n",
      "    >>> from sqlalchemy.types import Integer\n",
      "    >>> df.to_sql(name='integers', con=engine, index=False,\n",
      "    ...           dtype={\"A\": Integer()})\n",
      "    3\n",
      "    \n",
      "    >>> with engine.connect() as conn:\n",
      "    ...   conn.execute(text(\"SELECT * FROM integers\")).fetchall()\n",
      "    [(1,), (None,), (2,)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It shows all the Information of parameters in mySQL \n",
    "help(df.to_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9969"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running dataframe in mySQL        \n",
    "df.to_sql(name='walmart', con=engine_mysql, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(name='walmart', con=engine_psql, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
